# wildberries_parser

Парсер информации с страниц каталогов и продуктов интернет магазина Wildberries

Имеется 2 скрипта:
1. catalog_parser.py - Парсер каталогов
2. run.py - Парсер карточки продукта (Характеристики продукта)

requirements.txt - необходимые пакеты
settings.py - константы

Особенности:
1.Парсинг продуктов внутри каталогов с пагинацией. 
2.Выбор интересующих каталогов.
3.Все данные записываются в базу mysql.
4.Настройка таймаутов.
5.Запросы идут в 2 потока (Каталоги с чётным и нечётным id)
6.Использовалась библиотека beautifulsoup4, которая имеет очень хорошую документацию. Можно доработать скрипт, и получать любую информацию с странички товара.

Доработки:
1.В requirements.txt добавлен пакет "fake-useragent" можно доработать скрипт, для подкидывания разных useragent в запросах
2.В целом можно забирать любую информацию с карточки товара, достаточно просто поменять классы блоков в html.

Установка:

Необходимые пакеты:
1.Python ( 3.6+ )
2.PIP
3.MySQL ( Ver 14.14+ )

Обновляем pip:
  	py -m pip install --upgrade pip
Устанавливаем виртуальное окружение:
  	py -m pip install --user virtualenv
Создаём виртуальное окружение:
  	python3 -m venv env
Активируем окружение:
  	source env/bin/activate
Уставливаем необходимые зависимости:
	env/bin/pip install -r requirements.txt

Создаем базу данных в mysql:
	CREATE DATABASE wildberries;
Выполняем миграции из файла migration.sql

Заполняем необходимые данные в файле db.py (выбрать своё):
user='root', 
password='root',
host='127.0.0.1',
database='wildberries'

При необходимости меняем контсанты:
ALL_PRODUCT_ON_PAGE = 100 (Кол-во продуктов на странице каталога для парсинга (ВСЕГО!))
PAGE_LIMIT = 5 ( До какой страницы парсить каталог (пагинация) )
GET_PRODUCT_ON_PAGE = 100 (Сколько продуктов забираем с страницы)

CATALOGS_GET_TIMEOUT = 5 (Таймаут запроса к странице каталога)
PRODUCTS_CART_GET_TIMEOUT = 10 (Таймаут запроса к странице продукта)

PAGER_PARSE = False (Парсить ли страницы вместе с пагинацией, по умолчанию "False", если надо ставим "True")

SITE_URL = "https://www.wildberries.ru" (URL нашего сайта)

Если всё подготовили:
1. Забираем нужные каталоги с подкаталогами
В файле catalog_parser.py добавляем нужные нам родительские каталоги
Запускаем скрипт catalog_parser.py
2.Запускаем скрипт run.py. В консоль будут сыпаться результаты запросов.
3.После окончания, ищем всю информацию в созданых нами ранее таблицах mysql catalogs, products, tags (файл migration.sql).

Дополенения:
1.Если остановить скрипт посре работы, при следующем запуске он начнет работу с каталогов в которых не спарсились все продукты.
2.Имеется метод save_to_file, который записывает последнюю полученную html в файл page.html(Для отладки)
3.По умолчанию, скрипт run.py парсит продукты до 1000 штук в одном каталоге. Если нужно больше меняем на строке 93 в файле run.py:	"AND ( t.c < 1000 OR t.c IS NULL )", 1000 на нужное нам кол-во.


